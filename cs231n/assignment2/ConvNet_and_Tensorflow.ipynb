{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvNet and Tensorflow 2.0 beta\n",
    "\n",
    "이 notebook은 cs231n-2019 ConvNet numpy 구현 과제와 Tensorflow 2.0 beta 과제 정리본입니다.\n",
    "\n",
    "개인적인 정리이니 틀린 내용이 있을수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConvNet implementation with numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "X_train:  (49000, 3, 32, 32)\n",
      "y_train:  (49000,)\n",
      "X_val:  (1000, 3, 32, 32)\n",
      "y_val:  (1000,)\n",
      "X_test:  (1000, 3, 32, 32)\n",
      "y_test:  (1000,)\n"
     ]
    }
   ],
   "source": [
    "# As usual, a bit of setup\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cs231n.classifiers.cnn import *\n",
    "from cs231n.data_utils import get_CIFAR10_data\n",
    "from cs231n.gradient_check import eval_numerical_gradient_array, eval_numerical_gradient\n",
    "from cs231n.layers import *\n",
    "from cs231n.fast_layers import *\n",
    "from cs231n.solver import Solver\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def rel_error(x, y):\n",
    "  \"\"\" returns relative error \"\"\"\n",
    "  return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))\n",
    "\n",
    "# Load the (preprocessed) CIFAR10 data.\n",
    "\n",
    "data = get_CIFAR10_data()\n",
    "for k, v in data.items():\n",
    "  print('%s: ' % k, v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cs231n ConvNet implementation 과제는 cs231n/layers.py, cs231n/classifiers/cnn.py 를 구현하는 과제 입니다.\n",
    "\n",
    "따라서 python import 자체는 해당 파일에서 될것이고, 이 notebook 에서는 제가 구현한 소스코드를 해당 파일에서 가져와서 설명만 진행할것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cs231n/layers.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_forward_naive(x, w, b, conv_param):\n",
    "    \"\"\"\n",
    "    A naive implementation of the forward pass for a convolutional layer.\n",
    "\n",
    "    The input consists of N data points, each with C channels, height H and\n",
    "    width W. We convolve each input with F different filters, where each filter\n",
    "    spans all C channels and has height HH and width WW.\n",
    "\n",
    "    Input:\n",
    "    - x: Input data of shape (N, C, H, W)\n",
    "    - w: Filter weights of shape (F, C, HH, WW)\n",
    "    - b: Biases, of shape (F,)\n",
    "    - conv_param: A dictionary with the following keys:\n",
    "      - 'stride': The number of pixels between adjacent receptive fields in the\n",
    "        horizontal and vertical directions.\n",
    "      - 'pad': The number of pixels that will be used to zero-pad the input. \n",
    "        \n",
    "\n",
    "    During padding, 'pad' zeros should be placed symmetrically (i.e equally on both sides)\n",
    "    along the height and width axes of the input. Be careful not to modfiy the original\n",
    "    input x directly.\n",
    "\n",
    "    Returns a tuple of:\n",
    "    - out: Output data, of shape (N, F, H', W') where H' and W' are given by\n",
    "      H' = 1 + (H + 2 * pad - HH) / stride\n",
    "      W' = 1 + (W + 2 * pad - WW) / stride\n",
    "    - cache: (x, w, b, conv_param)\n",
    "    \"\"\"\n",
    "    out = None\n",
    "    ###########################################################################\n",
    "    # TODO: Implement the convolutional forward pass.                         #\n",
    "    # Hint: you can use the function np.pad for padding.                      #\n",
    "    ###########################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    batch_size, channel, height, width = x.shape\n",
    "    # input data 의 type 입니다.\n",
    "    # 이해가 쉽게 image의 예시를 들겠습니다.\n",
    "    # 배치 사이즈, image의 channel 수(보통 3 또는 4), input image의 size_Height, input image의 size_Width\n",
    "    filter_num, _, filter_height, filter_width = w.shape\n",
    "    # learnable filter의 shape 입니다.\n",
    "    # filter의 shape은 filter 개수, 입력 데이터 shape (without batch size)입니다.\n",
    "    # 따라서 filter 개수, Channel 개수, image size Height, image size Width 입니다.\n",
    "    stride, padding = conv_param['stride'], conv_param['pad']\n",
    "    output_height = 1 + (height + 2 * padding - filter_heig를ht) // stride\n",
    "    output_width = 1 + (width + 2 * padding - filter_width) // stride\n",
    "    # ConvNet의 output 인 Activation map의 size를 구하는 공식입니다.\n",
    "    \n",
    "    out = np.zeros((batch_size, filter_num, output_height, output_width))\n",
    "    x_pad = np.pad(x, ((0, 0), (0, 0), (padding, padding), (padding, padding)), mode='constant', constant_values=0)\n",
    "    # 이미지에 해당하는 영역에만 padding 적용\n",
    "    \n",
    "    for n in range(batch_size):\n",
    "        for f in range(filter_num):\n",
    "            for height_index in range(output_height):\n",
    "                for width_index in range(output_width):\n",
    "                    # 각 filter를 적용시켜 convolution 결과값인 scala 하나를 activation map 에 대입.\n",
    "                    out[n, f, height_index, width_index] = (\n",
    "                        np.sum(\n",
    "                            x_pad[n,\n",
    "                                  :, # 3 channel 모두 구한 후, np.sum을 해주기 위해 channel 전체 선택\n",
    "                                  height_index * stride:height_index * stride + filter_height,\n",
    "                                  width_index * stri를de:width_index * stride + filter_width]\n",
    "                                # filter size 만큼 input image 에서 가져오기\n",
    "                            * w[f]\n",
    "                            # filter size 인 W의 특정 filter 를 croped input 에 곱함으로, convolution 연산 진행.\n",
    "                            # element wise 곱셈\n",
    "                        )\n",
    "                        # element wise 곱셈이 끝나고, 전체 값을 더해주기\n",
    "                        + b[f]\n",
    "                        # bias 더하기\n",
    "                    )\n",
    "    \n",
    "    # 결국, croped input 에 대해서 element wise WX + b 를 하는것과 동일하다.\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ###########################################################################\n",
    "    #                             END OF YOUR CODE                            #\n",
    "    ###########################################################################\n",
    "    cache = (x, w, b, conv_param)\n",
    "    return out, cache"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ConvNet 의 Activation map size 구하는 방법\n",
    "\n",
    "![Untitled Diagram](https://user-images.githubusercontent.com/26921984/62833190-a233a580-bc75-11e9-8e53-5999bc96fcfd.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 47.  57.  67.]\n",
      "   [ 87.  97. 107.]\n",
      "   [127. 137. 147.]]]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[[[1,2,3,4], [5,6,7,8], [9,10,11,12], [13,14,15,16]]]])\n",
    "w = np.array([[[[1,2],[3,4]]]])\n",
    "b = np.array([3])\n",
    "conv_param = {\n",
    "    'stride': 1, \n",
    "    'pad': 0\n",
    "}\n",
    "out, cache = conv_forward_naive(x, w, b, conv_param)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ConvNet activation map 생성 과정\n",
    "\n",
    "![Untitled Diagram (1)](https://user-images.githubusercontent.com/26921984/62833376-b3ca7c80-bc78-11e9-895a-7b4db19fbcaa.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_backward_naive(dout, cache):\n",
    "    \"\"\"\n",
    "    A naive implementation of the backward pass for a convolutional layer.\n",
    "\n",
    "    Inputs:\n",
    "    - dout: Upstream derivatives.\n",
    "    - cache: A tuple of (x, w, b, conv_param) as in conv_forward_naive\n",
    "\n",
    "    Returns a tuple of:\n",
    "    - dx: Gradient with respect to x\n",
    "    - dw: Gradient with respect to w\n",
    "    - db: Gradient with respect to b\n",
    "    \"\"\"\n",
    "    dx, dw, db = None, None, None\n",
    "    ###########################################################################\n",
    "    # TODO: Implement the convolutional backward pass.                        #\n",
    "    ###########################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    x, w, b, conv_param = cache\n",
    "    batch_size, channel, height, width = x.shape\n",
    "    filter_num, _, filter_height, filter_width = w.shape\n",
    "    stride, padding = conv_param['stride'], conv_param['pad']\n",
    "    _, _, output_height, output_width = dout.shape\n",
    "    \n",
    "    \n",
    "    x_pad = np.pad(x, ((0, 0), (0, 0), (padding, padding), (padding, padding)), mode='constant', constant_values=0)\n",
    "    \n",
    "    dx_pad = np.zeros_like(x_pad)\n",
    "    dw = np.zeros_like(w)\n",
    "    db = np.zeros_like(b)\n",
    "    # data 준비 과정 설명은 생략\n",
    "    \n",
    "    for n in range(batch_size):\n",
    "        for f in range(filter_num):\n",
    "            db[f] += np.sum(dout[n, f])\n",
    "            for height_index in range(output_height):\n",
    "                for width_index in range(output_width):\n",
    "                    # 각 filter를 돌면서 backprop을 진행.\n",
    "                    # 각 learnable filter, W 가 어떻게 사용되었나 바라보자.\n",
    "                    # element wise W * X + b 가 진행되었었다.\n",
    "                    # 최종 gradient 는 각 element가 사용된 수식들에서 각각 구한 gradient들의 합이다.\n",
    "                    # batch normalization backprop을 구현해보면 잘 알 수 있다.\n",
    "                    # 예시) x -> WX + b -> output_a  -> output_a + output _b -> output_c\n",
    "                    #         -> ZX     -> output_ b\n",
    "                    # 위와같은 network 가 있다면, x 에 대한 gradient 는 output_c 부터 시작하여 흘러 내려오게 되는데,\n",
    "                    # WX+b 와 ZW 는 chain rule 에 의해 독립적으로 gradient를 구할 수 있다.\n",
    "                    # 따라서, x 의 gradient, dx 는 WX + b 로 부터 구한 dx_1, ZX 로 부터 구한 dx_2 의 합 이다.\n",
    "                    # dx = dx_1 + dx_2\n",
    "                    # 이 아이디어를 conv net 에 가져와보자.\n",
    "            \n",
    "                    dw[f] += (\n",
    "                        x_pad[n,\n",
    "                              :,\n",
    "                              height_index * stride:height_index * stride + filter_height,\n",
    "                              width_index * stride:width_index * stride + filter_width]\n",
    "                        * dout[n, f, height_index, width_index]\n",
    "                    )\n",
    "                    \n",
    "                    # W 에 대한 gradient를 구해야 한다.\n",
    "                    # forward 에서 element wise W * X + b 를 진행하였었다.\n",
    "                    # 이 식을 W 에 대해 편미분해보자.\n",
    "                    # 일단 bias 는 날아간다.\n",
    "                    # element wise 이므로 X 만 남게 된다.\n",
    "                    # 여기서 X 는 forward에서 crop 된 특정 영역의 input 이다.(shape == filter shape)\n",
    "                    # chain rule 을 적용해야하므로, dout 을 곱해준다.\n",
    "                    # 이로써, dW 의 일부분을 구하였다.\n",
    "                    # 그러면 어느 부분의 gradient를 구한것일까?\n",
    "                    # forward 에서 filter 가 sliding 하면서 건드렸던 모든 input 에 대해 dW 를 구한것이다.\n",
    "                    # 위에서 설명했듯이, W * X + b 에서, dW 를 구하기 위해서는\n",
    "                    # W 가 연산에 활용되었던 X 의 모든 구간에 대한 gradient 를 구해야하고, 해당 값에 대한 합을 구해야한다.\n",
    "                    # 따라서 대입이 아닌 += 연산을 활용한다.\n",
    "                    \n",
    "                    dx_pad[n,\n",
    "                           :,\n",
    "                           height_index * stride:height_index * stride + filter_height,\n",
    "                           width_index * stride:width_index * stride + filter_width] += (\n",
    "                        w[f] * dout[n, f, height_index, width_index]\n",
    "                    )\n",
    "                    \n",
    "                    # X 에 대한 gradient 또한 마찬가지로, X 와 같이 연산을 진행하였던 모든 W 에 대한 gradient 를 구하고, 합해야한다.\n",
    "                    \n",
    "    dx = dx_pad[:, :, padding:padding+height, padding:padding+width]\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ###########################################################################\n",
    "    #                             END OF YOUR CODE                            #\n",
    "    ###########################################################################\n",
    "    return dx, dw, db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Untitled Diagram (2)](https://user-images.githubusercontent.com/26921984/62833616-b8912f80-bc7c-11e9-878a-b79c35f15f6c.png)\n",
    "![Untitled Diagram (3)](https://user-images.githubusercontent.com/26921984/62833615-b8912f80-bc7c-11e9-882f-2762bf44b0c4.png)\n",
    "![Untitled Diagram (5)](https://user-images.githubusercontent.com/26921984/62833614-b8912f80-bc7c-11e9-8276-d8f8c4ba8cdd.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool_forward_naive(x, pool_param):\n",
    "    \"\"\"\n",
    "    A naive implementation of the forward pass for a max-pooling layer.\n",
    "\n",
    "    Inputs:\n",
    "    - x: Input data, of shape (N, C, H, W)\n",
    "    - pool_param: dictionary with the following keys:\n",
    "      - 'pool_height': The height of each pooling region\n",
    "      - 'pool_width': The width of each pooling region\n",
    "      - 'stride': The distance between adjacent pooling regions\n",
    "\n",
    "    No padding is necessary here. Output size is given by \n",
    "\n",
    "    Returns a tuple of:\n",
    "    - out: Output data, of shape (N, C, H', W') where H' and W' are given by\n",
    "      H' = 1 + (H - pool_height) / stride\n",
    "      W' = 1 + (W - pool_width) / stride\n",
    "    - cache: (x, pool_param)\n",
    "    \"\"\"\n",
    "    out = None\n",
    "    ###########################################################################\n",
    "    # TODO: Implement the max-pooling forward pass                            #\n",
    "    ###########################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    N, C, H, W = x.shape\n",
    "    pool_height = pool_param['pool_height']\n",
    "    pool_width = pool_param['pool_width']\n",
    "    stride = pool_param['stride']\n",
    "    \n",
    "    H_prime = 1 + (H - pool_height) // stride\n",
    "    W_prime = 1 + (W - pool_width) // stride\n",
    "    \n",
    "    out = np.zeros((N, C, H_prime, W_prime))\n",
    "    for n in range(N):\n",
    "        for h_prime in range(H_prime):\n",
    "            for w_prime in range(W_prime):\n",
    "                # max pooling forward 는 특별한 구현은 딱히 없다.\n",
    "                # 그저 axis 를 image height x width 영역에 맞추어 잘 걸어주면 끝.\n",
    "                out[n, :, h_prime, w_prime] = np.max(\n",
    "                    x[n, \n",
    "                      :, \n",
    "                      h_prime * stride:h_prime * stride + pool_height,\n",
    "                      w_prime * stride:w_prime * stride + pool_width,\n",
    "                     ], axis=(-1, -2))\n",
    "                \n",
    "                \n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ###########################################################################\n",
    "    #                             END OF YOUR CODE                            #\n",
    "    ###########################################################################\n",
    "    cache = (x, pool_param)\n",
    "    return out, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool_backward_naive(dout, cache):\n",
    "    \"\"\"\n",
    "    A naive implementation of the backward pass for a max-pooling layer.\n",
    "\n",
    "    Inputs:\n",
    "    - dout: Upstream derivatives\n",
    "    - cache: A tuple of (x, pool_param) as in the forward pass.\n",
    "\n",
    "    Returns:\n",
    "    - dx: Gradient with respect to x\n",
    "    \"\"\"\n",
    "    dx = None\n",
    "    ###########################################################################\n",
    "    # TODO: Implement the max-pooling backward pass                           #\n",
    "    ###########################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    x, pool_param = cache\n",
    "    N, C, H, W = x.shape\n",
    "    pool_height = pool_param['pool_height']\n",
    "    pool_width = pool_param['pool_width']\n",
    "    stride = pool_param['stride']\n",
    "    \n",
    "    H_prime = 1 + (H - pool_height) // stride\n",
    "    W_prime = 1 + (W - pool_width) // stride\n",
    "    \n",
    "    dx = np.zeros_like(x)\n",
    "    \n",
    "    for n in range(N):\n",
    "        for c in range(C):\n",
    "            for h_prime in range(H_prime):\n",
    "                for w_prime in range(W_prime):\n",
    "                    # max pool 의 back prop은 relu backprop 과 유사하다.\n",
    "                    # 결국 max pool 에 영향을 준 data, 즉 max 값으로 적용된 data만 pooling layer에서 연산에 적용되었고,\n",
    "                    # 나머지는 영향이 zero다.\n",
    "                    # 따라서, forward 단계에서 max 값으로 적용되었던 data 부분만 dout 을 흘려주고,\n",
    "                    # 나머지는 0을 넣어주면 max pool back prop이 완성된다.\n",
    "                    index = np.unravel_index(\n",
    "                        np.argmax(\n",
    "                            x[n, \n",
    "                              c, \n",
    "                              h_prime * stride:h_prime * stride + pool_height,\n",
    "                              w_prime * stride:w_prime * stride + pool_width,\n",
    "                             ]\n",
    "                        ),\n",
    "                        (pool_height, pool_width)\n",
    "                    )\n",
    "                    dx[n, \n",
    "                       c, \n",
    "                       h_prime * stride:h_prime * stride + pool_height,\n",
    "                       w_prime * stride:w_prime * stride + pool_width,\n",
    "                    ][index] = dout[n, c, h_prime, w_prime]\n",
    "                    \n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ###########################################################################\n",
    "    #                             END OF YOUR CODE                            #\n",
    "    ###########################################################################\n",
    "    return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![cs231n](https://user-images.githubusercontent.com/26921984/62834386-6ead4700-bc86-11e9-8d76-d9c52b7063b3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow 2.0 beta 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 과제에서는, 3 가지 방식으로 모델을 생성한다.\n",
    "각 방식은 다음과같은 특징을 가진다.\n",
    "\n",
    "| API           | Flexibility | Convenience |\n",
    "|---------------|-------------|-------------|\n",
    "| Barebone      | High        | Low         |\n",
    "| `tf.keras.Model`     | High        | Medium      |\n",
    "| `tf.keras.Sequential` | Low         | High        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Barebone Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Barebone 방식은 forward, backward 등을 모두 손수 돌려줘야한다.\n",
    "물론 numpy 구현보단 쉬운 방법이지만, tensorflow 를 사용해서 크게 편해진 점이 없다.\n",
    "각 layer 구현을 안한다 이 하나 정도 있는정도이다.\n",
    "\n",
    "심지어 gradient descent 도 함수로 돌려줘야했다....\n",
    "아무튼 시작해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    \"\"\"    \n",
    "    Input:\n",
    "    - TensorFlow Tensor of shape (N, D1, ..., DM)\n",
    "    \n",
    "    Output:\n",
    "    - TensorFlow Tensor of shape (N, D1 * ... * DM)\n",
    "    \"\"\"\n",
    "    N = tf.shape(x)[0]\n",
    "    return tf.reshape(x, (N, -1))\n",
    "\n",
    "def three_layer_convnet(x, params):\n",
    "    \"\"\"\n",
    "    A three-layer convolutional network with the architecture described above.\n",
    "    \n",
    "    Inputs:\n",
    "    - x: A TensorFlow Tensor of shape (N, H, W, 3) giving a minibatch of images\n",
    "    - params: A list of TensorFlow Tensors giving the weights and biases for the\n",
    "      network; should contain the following:\n",
    "      - conv_w1: TensorFlow Tensor of shape (KH1, KW1, 3, channel_1) giving\n",
    "        weights for the first convolutional layer.\n",
    "      - conv_b1: TensorFlow Tensor of shape (channel_1,) giving biases for the\n",
    "        first convolutional layer.\n",
    "      - conv_w2: TensorFlow Tensor of shape (KH2, KW2, channel_1, channel_2)\n",
    "        giving weights for the second convolutional layer\n",
    "      - conv_b2: TensorFlow Tensor of shape (channel_2,) giving biases for the\n",
    "        second convolutional layer.\n",
    "      - fc_w: TensorFlow Tensor giving weights for the fully-connected layer.\n",
    "        Can you figure out what the shape should be?\n",
    "      - fc_b: TensorFlow Tensor giving biases for the fully-connected layer.\n",
    "        Can you figure out what the shape should be?\n",
    "    \"\"\"\n",
    "    conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b = params\n",
    "    scores = None\n",
    "    ############################################################################\n",
    "    # TODO: Implement the forward pass for the three-layer ConvNet.            #\n",
    "    ############################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    \n",
    "    # layer 정보를 담는 구간이다.\n",
    "    x_pad = tf.pad(x, [\n",
    "        [0, 0],\n",
    "        [2, 2],\n",
    "        [2, 2],\n",
    "        [0, 0],\n",
    "    ], 'CONSTANT')\n",
    "    \n",
    "    # tf.nn 밑에 있는 layer 들을 사용할 수 있다.\n",
    "    # 하지만 다 수동으로 돌려줘야한다.. bias 도 수동으로 돌려준모습을 볼 수 있다.\n",
    "    conv1 = tf.nn.conv2d(x_pad, conv_w1, 1, padding='VALID') + conv_b1\n",
    "    relu1 = tf.nn.relu(conv1)\n",
    "    \n",
    "    conv1_pad = tf.pad(conv1, [[0, 0], [1, 1], [1, 1], [0, 0]], 'CONSTANT')\n",
    "    conv2 = tf.nn.conv2d(conv1_pad, conv_w2, 1, padding='VALID') + conv_b2\n",
    "    relu2 = tf.nn.relu(conv2)\n",
    "    \n",
    "    conv2_flat = flatten(relu2)\n",
    "    \n",
    "    # fc layer를 matmul로 직접 작업하였다.\n",
    "    \n",
    "    scores = tf.matmul(conv2_flat, fc_w) + fc_b\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ############################################################################\n",
    "    #                              END OF YOUR CODE                            #\n",
    "    ############################################################################\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(dset, x, model_fn, params):\n",
    "    \"\"\"\n",
    "    Check accuracy on a classification model, e.g. for validation.\n",
    "    \n",
    "    Inputs:\n",
    "    - dset: A Dataset object against which to check accuracy\n",
    "    - x: A TensorFlow placeholder Tensor where input images should be fed\n",
    "    - model_fn: the Model we will be calling to make predictions on x\n",
    "    - params: parameters for the model_fn to work with\n",
    "      \n",
    "    Returns: Nothing, but prints the accuracy of the model\n",
    "    \"\"\"\n",
    "    num_correct, num_samples = 0, 0\n",
    "    for x_batch, y_batch in dset:\n",
    "        scores_np = model_fn(x_batch, params).numpy()\n",
    "        y_pred = scores_np.argmax(axis=1)\n",
    "        num_samples += x_batch.shape[0]\n",
    "        num_correct += (y_pred == y_batch).sum()\n",
    "    acc = float(num_correct) / num_samples\n",
    "    print('Got %d / %d correct (%.2f%%)' % (num_correct, num_samples, 100 * acc))\n",
    "\n",
    "def training_step(model_fn, x, y, params, learning_rate):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # GradientTape 는 model 에 learnable variable 들의 gradient 를 저장해두는 변수이다.\n",
    "        scores = model_fn(x, params) # Forward pass of the model\n",
    "        loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=scores)\n",
    "        # softmax loss 를 구한다.\n",
    "        total_loss = tf.reduce_mean(loss)\n",
    "        # total loss 를 tf.reduce_mean 으로 평균을 구한다\n",
    "        grad_params = tape.gradient(total_loss, params)\n",
    "        # loss 를 이용하여 각 parameter들의 gradient를 구한다.\n",
    "        \n",
    "        # Make a vanilla gradient descent step on all of the model parameters\n",
    "        # Manually update the weights using assign_sub()\n",
    "        for w, grad_w in zip(params, grad_params):\n",
    "            # gradient descent 를 각 learnable variable들에 적용한다.\n",
    "            w.assign_sub(learning_rate * grad_w)\n",
    "                        \n",
    "        return total_loss    \n",
    "\n",
    "def create_matrix_with_kaiming_normal(shape):\n",
    "    if len(shape) == 2:\n",
    "        fan_in, fan_out = shape[0], shape[1]\n",
    "    elif len(shape) == 4:\n",
    "        fan_in, fan_out = np.prod(shape[:3]), shape[3]\n",
    "    return tf.keras.backend.random_normal(shape) * np.sqrt(2.0 / fan_in)\n",
    "\n",
    "def train_part2(model_fn, init_fn, learning_rate):\n",
    "    \"\"\"\n",
    "    Train a model on CIFAR-10.\n",
    "    \n",
    "    Inputs:\n",
    "    - model_fn: A Python function that performs the forward pass of the model\n",
    "      using TensorFlow; it should have the following signature:\n",
    "      scores = model_fn(x, params) where x is a TensorFlow Tensor giving a\n",
    "      minibatch of image data, params is a list of TensorFlow Tensors holding\n",
    "      the model weights, and scores is a TensorFlow Tensor of shape (N, C)\n",
    "      giving scores for all elements of x.\n",
    "    - init_fn: A Python function that initializes the parameters of the model.\n",
    "      It should have the signature params = init_fn() where params is a list\n",
    "      of TensorFlow Tensors holding the (randomly initialized) weights of the\n",
    "      model.\n",
    "    - learning_rate: Python float giving the learning rate to use for SGD.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    params = init_fn()  # Initialize the model parameters            \n",
    "        \n",
    "    for t, (x_np, y_np) in enumerate(train_dset):\n",
    "        # Run the graph on a batch of training data.\n",
    "        loss = training_step(model_fn, x_np, y_np, params, learning_rate)\n",
    "        \n",
    "        # Periodically print the loss and check accuracy on the val set.\n",
    "        if t % print_every == 0:\n",
    "            print('Iteration %d, loss = %.4f' % (t, loss))\n",
    "            check_accuracy(val_dset, x_np, model_fn, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_layer_convnet_init():\n",
    "    \"\"\"\n",
    "    Initialize the weights of a Three-Layer ConvNet, for use with the\n",
    "    three_layer_convnet function defined above.\n",
    "    You can use the `create_matrix_with_kaiming_normal` helper!\n",
    "    \n",
    "    Inputs: None\n",
    "    \n",
    "    Returns a list containing:\n",
    "    - conv_w1: TensorFlow tf.Variable giving weights for the first conv layer\n",
    "    - conv_b1: TensorFlow tf.Variable giving biases for the first conv layer\n",
    "    - conv_w2: TensorFlow tf.Variable giving weights for the second conv layer\n",
    "    - conv_b2: TensorFlow tf.Variable giving biases for the second conv layer\n",
    "    - fc_w: TensorFlow tf.Variable giving weights for the fully-connected layer\n",
    "    - fc_b: TensorFlow tf.Variable giving biases for the fully-connected layer\n",
    "    \"\"\"\n",
    "    params = None\n",
    "    ############################################################################\n",
    "    # TODO: Initialize the parameters of the three-layer network.              #\n",
    "    ############################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    \n",
    "    # tf.Variable 로 Variable들을 만들어준다.\n",
    "    conv_w1 = tf.Variable(create_matrix_with_kaiming_normal((5,5,3,32)))\n",
    "    conv_b1 = tf.Variable(tf.zeros([32]))\n",
    "    conv_w2 = tf.Variable(create_matrix_with_kaiming_normal((3,3,32,16)))\n",
    "    conv_b2 = tf.Variable(tf.zeros([16]))\n",
    "    fc_w = tf.Variable(create_matrix_with_kaiming_normal((32 * 32 *16,10)))\n",
    "    fc_b = tf.Variable(tf.zeros([10]))\n",
    "    params = [conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b]\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ############################################################################\n",
    "    #                             END OF YOUR CODE                             #\n",
    "    ############################################################################\n",
    "    return params\n",
    "\n",
    "learning_rate = 3e-3\n",
    "train_part2(three_layer_convnet, three_layer_convnet_init, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Model Subclassing API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gradient 계산이나 Variable선언 필요 없이, tf.keras.layers 밑에 구현되어있는 layer들을 가져다 쓰면 된다.\n",
    "layer가 실행되는 순서를 call method에 선언해주면된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThreeLayerConvNet(tf.keras.Model):\n",
    "    def __init__(self, channel_1, channel_2, num_classes):\n",
    "        super(ThreeLayerConvNet, self).__init__()\n",
    "        ########################################################################\n",
    "        # TODO: Implement the __init__ method for a three-layer ConvNet. You   #\n",
    "        # should instantiate layer objects to be used in the forward pass.     #\n",
    "        ########################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "        initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
    "        self.conv1 = tf.keras.layers.Conv2D(\n",
    "            filters=channel_1,\n",
    "            kernel_size=[5, 5],\n",
    "            strides=[1, 1],\n",
    "            padding='valid',\n",
    "            activation='relu',\n",
    "            kernel_initializer=initializer\n",
    "        )\n",
    "        self.conv2 = tf.keras.layers.Conv2D(\n",
    "            filters=channel_2,\n",
    "            kernel_size=[3, 3],\n",
    "            strides=[1, 1],\n",
    "            padding='valid',\n",
    "            activation='relu',\n",
    "            kernel_initializer=initializer\n",
    "        )\n",
    "        self.fc1 = tf.keras.layers.Dense(\n",
    "            units=num_classes,\n",
    "            kernel_initializer=initializer,\n",
    "            activation='softmax'\n",
    "        )\n",
    "\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        ########################################################################\n",
    "        #                           END OF YOUR CODE                           #\n",
    "        ########################################################################\n",
    "        \n",
    "    def call(self, x, training=False):\n",
    "        scores = None\n",
    "        ########################################################################\n",
    "        # TODO: Implement the forward pass for a three-layer ConvNet. You      #\n",
    "        # should use the layer objects defined in the __init__ method.         #\n",
    "        ########################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        x = tf.pad(x, [[0, 0], [2, 2], [2, 2], [0, 0]], 'CONSTANT')\n",
    "        x = self.conv1(x)\n",
    "        x = tf.pad(x, [[0, 0], [1, 1], [1, 1], [0, 0]], 'CONSTANT')\n",
    "        x = self.conv2(x)\n",
    "        x = tf.keras.layers.Flatten()(x)\n",
    "        scores = self.fc1(x)\n",
    "\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        ########################################################################\n",
    "        #                           END OF YOUR CODE                           #\n",
    "        ########################################################################        \n",
    "        return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow 2.0 부터는 Eager Training을 지원한다.\n",
    "\n",
    "즉, static graph를 만들고 적용하는 일이 없어진다는것이다.\n",
    "\n",
    "이를 위해서 tf.GradientTape 에 gradient를 저장해둔뒤, 선언해둔 optimizer(tf.keras.optimizers) 의 method 인 apply_gradients 로 gradient descent작업이 끝난다.\n",
    "\n",
    "또한, metric과 log작업도 tf.keras.metrics method들을 사용하면 편하게 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_part34(model_init_fn, optimizer_init_fn, num_epochs=1, is_training=False):\n",
    "    \"\"\"\n",
    "    Simple training loop for use with models defined using tf.keras. It trains\n",
    "    a model for one epoch on the CIFAR-10 training set and periodically checks\n",
    "    accuracy on the CIFAR-10 validation set.\n",
    "    \n",
    "    Inputs:\n",
    "    - model_init_fn: A function that takes no parameters; when called it\n",
    "      constructs the model we want to train: model = model_init_fn()\n",
    "    - optimizer_init_fn: A function which takes no parameters; when called it\n",
    "      constructs the Optimizer object we will use to optimize the model:\n",
    "      optimizer = optimizer_init_fn()\n",
    "    - num_epochs: The number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints progress during trainingn\n",
    "    \"\"\"    \n",
    "    with tf.device(device):\n",
    "\n",
    "        # Compute the loss like we did in Part II\n",
    "        loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "        \n",
    "        model = model_init_fn()\n",
    "        optimizer = optimizer_init_fn()\n",
    "        \n",
    "        train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "        train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "    \n",
    "        val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "        val_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='val_accuracy')\n",
    "        \n",
    "        t = 0\n",
    "        for epoch in range(num_epochs):\n",
    "            \n",
    "            # Reset the metrics - https://www.tensorflow.org/alpha/guide/migration_guide#new-style_metrics\n",
    "            train_loss.reset_states()\n",
    "            train_accuracy.reset_states()\n",
    "            \n",
    "            for x_np, y_np in train_dset:\n",
    "                with tf.GradientTape() as tape:\n",
    "                    \n",
    "                    # Use the model function to build the forward pass.\n",
    "                    scores = model(x_np, training=is_training)\n",
    "                    loss = loss_fn(y_np, scores)\n",
    "      \n",
    "                    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "                    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "                    \n",
    "                    # Update the metrics\n",
    "                    train_loss.update_state(loss)\n",
    "                    train_accuracy.update_state(y_np, scores)\n",
    "                    \n",
    "                    if t % print_every == 0:\n",
    "                        val_loss.reset_states()\n",
    "                        val_accuracy.reset_states()\n",
    "                        for test_x, test_y in val_dset:\n",
    "                            # During validation at end of epoch, training set to False\n",
    "                            prediction = model(test_x, training=False)\n",
    "                            t_loss = loss_fn(test_y, prediction)\n",
    "\n",
    "                            val_loss.update_state(t_loss)\n",
    "                            val_accuracy.update_state(test_y, prediction)\n",
    "                        \n",
    "                        template = 'Iteration {}, Epoch {}, Loss: {}, Accuracy: {}, Val Loss: {}, Val Accuracy: {}'\n",
    "                        print (template.format(t, epoch+1,\n",
    "                                             train_loss.result(),\n",
    "                                             train_accuracy.result()*100,\n",
    "                                             val_loss.result(),\n",
    "                                             val_accuracy.result()*100))\n",
    "                    t += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Sequential API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras model subclasse api 또한 편리했지만, 보통의 model들은 sequential한 layer구조를 가질때가 많다.\n",
    "\n",
    "따라서 단순한 sequential한 network를 만들때에는 tf.Keras.Sequential을 이용하면 편하다.\n",
    "\n",
    "아래 코드 처럼 layer를 list에 넣고 tf.keras.Sequential 에 넣어주기만 하면 끝이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init_fn():\n",
    "    model = None\n",
    "    ############################################################################\n",
    "    # TODO: Construct a three-layer ConvNet using tf.keras.Sequential.         #\n",
    "    ############################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    input_shape = (32, 32, 3)\n",
    "    channel_1,channel_2, num_classes = 32, 16, 10\n",
    "    \n",
    "    initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
    "    \n",
    "    layers = [\n",
    "        tf.keras.layers.Conv2D(\n",
    "            filters=channel_1,\n",
    "            kernel_size=[5, 5],\n",
    "            strides=[1, 1],\n",
    "            padding='valid',\n",
    "            activation='relu',\n",
    "            kernel_initializer=initializer\n",
    "        ),\n",
    "        tf.keras.layers.Conv2D(\n",
    "            filters=channel_2,\n",
    "            kernel_size=[3, 3],\n",
    "            strides=[1, 1],\n",
    "            padding='valid',\n",
    "            activation='relu',\n",
    "            kernel_initializer=initializer\n",
    "        ),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(\n",
    "            units=num_classes,\n",
    "            kernel_initializer=initializer,\n",
    "            activation='softmax'\n",
    "        ),\n",
    "    ]\n",
    "    \n",
    "    model = tf.keras.Sequential(layers)\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ############################################################################\n",
    "    #                            END OF YOUR CODE                              #\n",
    "    ############################################################################\n",
    "    return model\n",
    "\n",
    "learning_rate = 5e-4\n",
    "def optimizer_init_fn():\n",
    "    optimizer = None\n",
    "    ############################################################################\n",
    "    # TODO: Complete the implementation of model_fn.                           #\n",
    "    ############################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    optimizer = tf.keras.optimizers.SGD(\n",
    "        learning_rate=learning_rate, momentum=0.9, nesterov=True\n",
    "    )\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ############################################################################\n",
    "    #                           END OF YOUR CODE                               #\n",
    "    ############################################################################\n",
    "    return optimizer\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리는 지금까지 tensorflow 의 eager execution을 사용하였다.\n",
    "물론 충분히 high level api이지만, keras는 이 보다 더 high level Training api를 제공한다.\n",
    "\n",
    "바로 model.fit 이다.\n",
    "\n",
    "기존에는 아래 작업으로 학습을 진행하였다면, 이 코드를 짜지 않고, fit 함수에 적절한 optimizerr, loss function, metric option을 주면 알아서 학습을 진행한다.\n",
    "\n",
    "```python\n",
    "for x_np, y_np in train_dset:\n",
    "                with tf.GradientTape() as tape:\n",
    "    scores = model(x_np, training=is_training)\n",
    "                        loss = loss_fn(y_np, scores)\n",
    "                        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "                        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_init_fn()\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=1, validation_data=(X_val, y_val))\n",
    "model.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs231n.env",
   "language": "python",
   "name": ".env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
